{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vector autoregression model**.  \n",
    "The vector autoregression model VAR(p) models the relationship of two or more time\n",
    "series. In this model, each time series has an impact on the others. This means that\n",
    "past values of one time series affect the other time series, and vice versa.\n",
    "The VAR(p) model can be seen as a generalization of the AR(p) model that allows for\n",
    "multiple time series. Just like in the AR(p) model, the order p of the VAR(p) model\n",
    "determines how many lagged values impact the present value of a series. In this\n",
    "model, however, we also include lagged values of other time series.\n",
    "For two time series, the general equation for the VAR(p) model is a linear combination\n",
    "of a vector of constants, past values of both time series, and a vector of error terms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the time series must be stationary to apply the VAR model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Granger causality test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a statistical test that helps us deter-\n",
    "mine if past values of a time series y2,t can help forecast time series y1,t . If that is the\n",
    "case, then we say that y2,t Granger-causes y1,t .\n",
    "Note that the Granger causality test is restricted to predictive causality, as we are\n",
    "only determining whether past values of a time series are statistically significant in\n",
    "predicting another time series. Furthermore, the test requires both time series to be stationary in order for the results to be valid. Also, the Granger causality test tests cau-\n",
    "sality only in one direction; we must repeat the test to verify that y1,t also Granger-\n",
    "causes y2,t in order for the VAR model to be valid. Otherwise, we must resort to the\n",
    "SARIMAX model and predict each time series separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis for this test states that y2,t does not Granger-cause y1,t . Again,\n",
    "we will use the p-value with a critical value of 0.05 to determine whether we will reject\n",
    "the null hypothesis or not.In the case where the returned p-value of the Granger cau-\n",
    "sality test is less than 0.05, we can reject the null hypothesis and say that y2,t Granger-\n",
    "causes y1,t ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests, adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_econ_data = sm.datasets.macrodata.load_pandas().data\n",
    "macro_econ_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10,8))\n",
    "\n",
    "ax1.plot(macro_econ_data['realdpi'])\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Real disposable income (k$)')\n",
    "ax1.set_title('realdpi')\n",
    "ax1.spines['top'].set_alpha(0)\n",
    "\n",
    "ax2.plot(macro_econ_data['realcons'])\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Real consumption (k$)')\n",
    "ax2.set_title('realcons')\n",
    "ax2.spines['top'].set_alpha(0)\n",
    "\n",
    "plt.xticks(np.arange(0, 208, 16), np.arange(1959, 2010, 4))\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for stationarity with augmented Dickey-Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_fuller_result_1 = adfuller(macro_econ_data['realdpi'])\n",
    "\n",
    "print('realdpi')\n",
    "print(f'ADF Statistic: {ad_fuller_result_1[0]}')\n",
    "print(f'p-value: {ad_fuller_result_1[1]}')\n",
    "\n",
    "print('\\n---------------------\\n')\n",
    "\n",
    "ad_fuller_result_2 = adfuller(macro_econ_data['realcons'])\n",
    "\n",
    "print('realcons')\n",
    "print(f'ADF Statistic: {ad_fuller_result_2[0]}')\n",
    "print(f'p-value: {ad_fuller_result_2[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot reject the null hypothesis for both of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_fuller_result_1 = adfuller(macro_econ_data['realdpi'].diff()[1:])\n",
    "\n",
    "print('realdpi')\n",
    "print(f'ADF Statistic: {ad_fuller_result_1[0]}')\n",
    "print(f'p-value: {ad_fuller_result_1[1]}')\n",
    "\n",
    "print('\\n---------------------\\n')\n",
    "\n",
    "ad_fuller_result_2 = adfuller(macro_econ_data['realcons'].diff()[1:])\n",
    "\n",
    "print('realcons')\n",
    "print(f'ADF Statistic: {ad_fuller_result_2[0]}')\n",
    "print(f'p-value: {ad_fuller_result_2[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is stationary after differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from tqdm import tqdm_notebook\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "\n",
    "def optimize_VAR(endog: Union[pd.Series, list]) -> pd.DataFrame:\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in tqdm_notebook(range(15)):\n",
    "        try:\n",
    "            model = VARMAX(endog, order=(i, 0)).fit(dips=False)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        aic = model.aic\n",
    "        results.append([i, aic])\n",
    "        \n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.columns = ['p', 'AIC']\n",
    "    \n",
    "    result_df = result_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endog = macro_econ_data[['realdpi', 'realcons']]\n",
    "\n",
    "endog_diff = macro_econ_data[['realdpi', 'realcons']].diff()[1:]\n",
    "\n",
    "train = endog_diff[:162]\n",
    "test = endog_diff[162:]\n",
    "\n",
    "result_df = optimize_VAR(train)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function tests if the second variable Granger-causes the first one. Here we thus test\n",
    "if realcons Granger-causes realdpi. We then pass the number of lags in a list, which in\n",
    "our case is 3. Note that the series are differenced to make them stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('realcons Granger-causes realdpi?\\n')\n",
    "print('------------------')\n",
    "granger_1 = grangercausalitytests(macro_econ_data[['realdpi', 'realcons']].diff()[1:], [3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nrealdpi Granger-causes realcons?\\n')\n",
    "print('------------------')\n",
    "granger_2 = grangercausalitytests(macro_econ_data[['realcons', 'realdpi']].diff()[1:], [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the Granger causality test for both variables returns a p-value smaller than\n",
    "0.05 in both cases. Therefore, we can reject the null hypothesis and conclude that\n",
    "realdpi Granger-causes realcons, and realcons Granger-causes realdpi. Our\n",
    "VAR(3) model is thus valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = VARMAX(train, order=(3,0))\n",
    "best_model_fit = best_model.fit(disp=False)\n",
    "\n",
    "print(best_model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realdpi\n",
    "# Passing variable=0 specifies that we want plots for the residuals of\n",
    "# realdpi, since it is the first variable that was passed to the VAR model\n",
    "best_model_fit.plot_diagnostics(figsize=(10,8), variable=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realcons\n",
    "best_model_fit.plot_diagnostics(figsize=(10,8), variable=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realgdp_residuals = best_model_fit.resid['realdpi']\n",
    "\n",
    "lbvalue, pvalue = acorr_ljungbox(realgdp_residuals, np.arange(1, 11, 1))\n",
    "\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realcons_residuals = best_model_fit.resid['realcons']\n",
    "\n",
    "lbvalue, pvalue = acorr_ljungbox(realcons_residuals, np.arange(1, 11, 1))\n",
    "\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_forecast(df: pd.DataFrame, train_len: int, horizon: int, window: int, method: str) -> list:\n",
    "    \n",
    "    total_len = train_len + horizon\n",
    "    end_idx = train_len\n",
    "    \n",
    "    if method == 'VAR':\n",
    "\n",
    "        realdpi_pred_VAR = []\n",
    "        realcons_pred_VAR = []\n",
    "        \n",
    "        for i in range(train_len, total_len, window):\n",
    "            model = VARMAX(df[:i], order=(3,0))\n",
    "            res = model.fit(disp=False)\n",
    "            predictions = res.get_prediction(0, i + window - 1)\n",
    "            \n",
    "            oos_pred_realdpi = predictions.predicted_mean.iloc[-window:]['realdpi']\n",
    "            oos_pred_realcons = predictions.predicted_mean.iloc[-window:]['realcons']\n",
    "            \n",
    "            realdpi_pred_VAR.extend(oos_pred_realdpi)\n",
    "            realcons_pred_VAR.extend(oos_pred_realcons)\n",
    "        \n",
    "        return realdpi_pred_VAR, realcons_pred_VAR\n",
    "    \n",
    "    elif method == 'last':\n",
    "        realdpi_pred_last = []\n",
    "        realcons_pred_last = []\n",
    "        \n",
    "        for i in range(train_len, total_len, window):\n",
    "            \n",
    "            realdpi_last = df[:i].iloc[-1]['realdpi']\n",
    "            realcons_last = df[:i].iloc[-1]['realcons']\n",
    "            \n",
    "            realdpi_pred_last.extend(realdpi_last for _ in range(window))\n",
    "            realcons_pred_last.extend(realcons_last for _ in range(window))\n",
    "            \n",
    "        return realdpi_pred_last, realcons_pred_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LEN = len(train)\n",
    "HORIZON = len(test)\n",
    "WINDOW = 4\n",
    "\n",
    "realdpi_pred_VAR, realcons_pred_VAR = rolling_forecast(endog_diff, TRAIN_LEN, HORIZON, WINDOW, 'VAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = endog[163:]\n",
    "\n",
    "test['realdpi_pred_VAR'] = pd.Series()\n",
    "test['realdpi_pred_VAR'] = endog.iloc[162]['realdpi'] + np.cumsum(realdpi_pred_VAR)\n",
    "\n",
    "test['realcons_pred_VAR'] = pd.Series()\n",
    "test['realcons_pred_VAR'] = endog.iloc[162]['realcons'] + np.cumsum(realcons_pred_VAR)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realdpi_pred_last, realcons_pred_last = rolling_forecast(endog, TRAIN_LEN, HORIZON, WINDOW, 'last')\n",
    "\n",
    "test['realdpi_pred_last'] = realdpi_pred_last\n",
    "test['realcons_pred_last'] = realcons_pred_last\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10,8))\n",
    "\n",
    "ax1.plot(macro_econ_data['realdpi'])\n",
    "ax1.plot(test['realdpi_pred_VAR'], 'k--', label='VAR')\n",
    "ax1.plot(test['realdpi_pred_last'], 'r:', label='last')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Real disposable income ($))')\n",
    "ax1.set_title('realdpi')\n",
    "ax1.spines['top'].set_alpha(0)\n",
    "ax1.axvspan(163, 202, color='#808080', alpha=0.2)\n",
    "ax1.set_xlim(100, 202)\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "ax2.plot(macro_econ_data['realcons'])\n",
    "ax2.plot(test['realcons_pred_VAR'], 'k--', label='VAR')\n",
    "ax2.plot(test['realcons_pred_last'], 'r:', label='last')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Real consumption (k$)')\n",
    "ax2.set_title('realcons')\n",
    "ax2.spines['top'].set_alpha(0)\n",
    "ax2.axvspan(163, 202, color='#808080', alpha=0.2)\n",
    "ax2.set_xlim(100, 202)\n",
    "ax2.legend(loc=2)\n",
    "\n",
    "plt.xticks(np.arange(0, 208, 16), np.arange(1959, 2010, 4))\n",
    "plt.xlim(100, 202)\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_realdpi_VAR = mape(test['realdpi'], test['realdpi_pred_VAR'])\n",
    "mape_realdpi_last = mape(test['realdpi'], test['realdpi_pred_last'])\n",
    "\n",
    "mape_realcons_VAR = mape(test['realcons'], test['realcons_pred_VAR'])\n",
    "mape_realcons_last = mape(test['realcons'], test['realcons_pred_last'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10,6))\n",
    "\n",
    "x = ['last', 'VAR']\n",
    "y1 = [mape_realdpi_last, mape_realdpi_VAR]\n",
    "y2 = [mape_realcons_last, mape_realcons_VAR]\n",
    "\n",
    "ax1.bar(x, y1)\n",
    "ax1.set_xlabel('Methods')\n",
    "ax1.set_ylabel('MAPE (%)')\n",
    "ax1.set_title('realdpi')\n",
    "ax1.set_ylim(0, 3.5)\n",
    "\n",
    "ax2.bar(x,y2)\n",
    "ax2.set_xlabel('Methods')\n",
    "ax2.set_ylabel('MAPE (%)')\n",
    "ax2.set_title('realcons')\n",
    "ax2.set_ylim(0, 3)\n",
    "\n",
    "for index, value in enumerate(y1):\n",
    "    ax1.text(x=index, y=value + 0.05, s=str(round(value,2)), ha='center')\n",
    "    \n",
    "for index, value in enumerate(y2):\n",
    "    ax2.text(x=index, y=value + 0.05, s=str(round(value,2)), ha='center')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
